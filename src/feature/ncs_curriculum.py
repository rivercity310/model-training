import numpy as np
import pandas as pd
import networkx as nx
import faiss
import os
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
from dotenv import load_dotenv
from sqlmodel import create_engine

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DB Engine
url = os.getenv("DATABASE_URL")
engine = create_engine(url=url, echo=True)

# ê²½ë¡œ
EMB_TABLE_NAME = "tb_ncs_comp_unit_emb_test"
ROOT_DIR = Path(os.getenv("PROJECT_ROOT_DIR")).resolve()
CSV_DIR_PATH = ROOT_DIR / "data" / "csv"
ANALYSIS_DIR_PATH = ROOT_DIR / "data" / "analysis"
DATA_FILE_PATH = CSV_DIR_PATH / f"{EMB_TABLE_NAME}.csv"


def initialize_csv():
    query = f"""
        SELECT
        unit.comp_unit_id,
        unit.comp_unit_name,
        unit.comp_unit_def,
        unit.comp_unit_level,
        emb.embedding_unit_def
        FROM {EMB_TABLE_NAME} emb
        JOIN tb_ncs_comp_unit unit
        ON emb.comp_unit_id = unit.comp_unit_id
        WHERE unit.useflag = 'Y' AND unit.use_ncs = 'Y'
    """

    df = pd.read_sql(query, engine)
    df.to_csv(DATA_FILE_PATH, index=False, encoding="utf-8-sig")
    print(f"ì„±ê³µì ìœ¼ë¡œ {len(df)}ê±´ì˜ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")


def build_skill_graph(data: pd.DataFrame, k_neighbors=20, n_probes=10):
    """
    Pandas DataFrame í˜•íƒœì˜ NCS ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì—­ëŸ‰ ê´€ê³„ë§(ê·¸ë˜í”„) êµ¬ì¶•
    FAISSë¥¼ ì‚¬ìš©í•´ì„œ ë¸Œë£¨íŠ¸ í¬ìŠ¤ ë°©ì‹ì´ ì•„ë‹Œ ANN ê¸°ë°˜ìœ¼ë¡œ ì‹œê°„ ë³µì¡ë„ ê°œì„ 
    """
    # 1. DBì—ì„œ ë¶ˆëŸ¬ì˜¨ ì„ë² ë”© ë²¡í„°ë¥¼ Faissê°€ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
    # - (ë°ì´í„° ê°œìˆ˜, ì„ë² ë”© ì°¨ì›) í˜•íƒœì˜ 2D Numpy ë°°ì—´
    # - float32 ìë£Œí˜•
    embedding_unit_def = np.array(list(data['embedding_unit_def'])).astype('float32')
    embedding_dimension = embedding_unit_def.shape[1]

    # 2. Faiss ì¸ë±ìŠ¤ ìƒì„± ë° ë²¡í„° ì¶”ê°€
    # IndexFlatL2ëŠ” ê°€ì¥ ê¸°ë³¸ì ì¸ L2 ê±°ë¦¬(ìœ í´ë¦¬ë“œ ê±°ë¦¬) ê¸°ë°˜ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ L2 ê±°ë¦¬ëŠ” ì •ê·œí™”ëœ(normalized) ë²¡í„°ì—ì„œëŠ” ë™ì¼í•œ ìˆœì„œë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.
    quantizer = faiss.IndexFlatIP(embedding_dimension)
    nlist = int(np.sqrt(len(embedding_unit_def)))

    index = faiss.IndexIVFFlat(quantizer, embedding_dimension, nlist, faiss.METRIC_INNER_PRODUCT)
    index.train(embedding_unit_def)
    index.add(embedding_unit_def)
    index.nprobe = n_probes

    print(f"Faiss ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ. ì´ {index.ntotal}ê°œì˜ ë²¡í„°ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 3. ê° ë²¡í„°ì— ëŒ€í•´ ê°€ì¥ ê°€ê¹Œìš´ Kê°œì˜ ì´ì›ƒ ê²€ìƒ‰
    # search(ìê¸° ìì‹ ì„ í¬í•¨í•œ ëª¨ë“  ë²¡í„°, ì°¾ì„ ì´ì›ƒì˜ ìˆ˜ k+1)
    # ìê¸° ìì‹ ë„ ê²°ê³¼ì— í¬í•¨ë˜ë¯€ë¡œ k+1ê°œ ê²€ìƒ‰
    distances, indices = index.search(embedding_unit_def, k_neighbors + 1)

    # ë°©í–¥ì„± ìˆëŠ” ê·¸ë˜í”„(DiGraph) ìƒì„±
    G = nx.DiGraph()

    # ê·¸ë˜í”„ì— ë…¸ë“œ(ëŠ¥ë ¥ë‹¨ìœ„) ì¶”ê°€
    for index, row in data.iterrows():
        G.add_node(row['comp_unit_id'], name=row['comp_unit_name'], level=row['comp_unit_level'])

    # 3. ì—£ì§€ ìƒì„± ì‹œ, ë¯¸ë¦¬ ê³„ì‚°ëœ ì„ë² ë”©ìœ¼ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
    for i in tqdm(range(len(data)), desc="ì—£ì§€ ìƒì„± ì¤‘..."):
        level_i = int(data.loc[i, 'comp_unit_level'])

        for neighbor_idx, dist in zip(indices[i], distances[i]):
            if i == neighbor_idx or neighbor_idx < 0:
                continue

            level_j = int(data.loc[neighbor_idx, 'comp_unit_level'])

            if level_i >= level_j:
                continue

            # NCS ë ˆë²¨ ì°¨ì´ê°€ í´ìˆ˜ë¡ íŒ¨ë„í‹° ë¶€ì—¬ (ìš°ì„  ìˆœìœ„ì—ì„œ ë°€ë ¤ë‚¨)
            level_gap_penalty = (level_j - level_i - 1) * 0.5
            weight = (1 - dist) + level_gap_penalty

            G.add_edge(data.loc[i, 'comp_unit_id'], data.loc[neighbor_idx, 'comp_unit_id'], weight=weight)

    return G


# --- 2ë‹¨ê³„: ê²½ë¡œ íƒìƒ‰ ë° ê°­ ë¶„ì„ ---
def find_career_path(graph: nx.DiGraph, current_skill_ids: list, target_skill_id: str):
    """
    ì£¼ì–´ì§„ ê·¸ë˜í”„ì—ì„œ í˜„ì¬ ì—­ëŸ‰ìœ¼ë¡œë¶€í„° ëª©í‘œ ì—­ëŸ‰ê¹Œì§€ì˜ ìµœì  ê²½ë¡œì™€ ìŠ¤í‚¬ ê°­ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    best_path = None
    min_path_cost = float('inf')

    # í˜„ì¬ ë³´ìœ í•œ ì—¬ëŸ¬ ìŠ¤í‚¬ ì¤‘ ì–´ë–¤ ìŠ¤í‚¬ì—ì„œ ì¶œë°œí•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ìœ¨ì ì¸ì§€ íƒìƒ‰
    for start_id in current_skill_ids:
        try:
            # ë‹¤ìµìŠ¤íŠ¸ë¼ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ìµœë‹¨ ê²½ë¡œ(ìµœì†Œ ë¹„ìš© ê²½ë¡œ) íƒìƒ‰
            path = nx.dijkstra_path(graph, source=start_id, target=target_skill_id, weight='weight')
            path_cost = nx.dijkstra_path_length(graph, source=start_id, target=target_skill_id, weight='weight')

            if path_cost < min_path_cost:
                min_path_cost = path_cost
                best_path = path

        except nx.NetworkXNoPath:
            # ê²½ë¡œê°€ ì—†ëŠ” ê²½ìš°ëŠ” ë¬´ì‹œ
            continue

    if best_path is None:
        return None, None  # ê²½ë¡œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°

    # ìŠ¤í‚¬ ê°­ = ì¶”ì²œ ê²½ë¡œ ì¤‘ í˜„ì¬ ë³´ìœ  ì—­ëŸ‰ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€
    skill_gap = [skill_id for skill_id in best_path if skill_id not in current_skill_ids]

    return best_path, skill_gap


def get_course_from_node(comp_unit_id, engine):
    query = """
        SELECT sbj_nm FROM tb_cos_m
        WHERE cos_id IN (
            SELECT cos_id FROM tb_cos_ncs_mat_d mat
            WHERE mat.comp_unit_id = %(comp_id)s
            AND mat.useflag = 'Y'
            AND mat.del_yn = 'N'
            AND mat.match_rate >= 75
            ORDER BY mat.match_rate DESC
            LIMIT 10
        ) 
        AND useflag = 'Y' 
        AND del_yn = 'N'
    """

    params = {'comp_id': comp_unit_id}
    df = pd.read_sql(query, engine, params=params)

    if df.empty:
        return []

    # dict.fromkeys()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©° ì¤‘ë³µ ì œê±°
    sbj_nm_list = df['sbj_nm'].tolist()
    return list(dict.fromkeys(sbj_nm_list))


if __name__ == "__main__":
    if not os.path.exists(CSV_DIR_PATH):
        CSV_DIR_PATH.mkdir(parents=True)

    # CSV íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° DBì—ì„œ ì´ˆê¸°í™”
    if not os.path.exists(DATA_FILE_PATH):
        initialize_csv()

    # CSV íŒŒì¼ ì½ì–´ì˜¤ê³  ì„ë² ë”© ì»¬ëŸ¼ ê°€ê³µ
    df = pd.read_csv(DATA_FILE_PATH)
    df['comp_unit_id'] = df['comp_unit_id'].astype(str).str.strip()
    df['embedding_unit_def'] = df['embedding_unit_def'].apply(
        lambda x: np.fromstring(x.strip('[]'), sep=',')
    )

    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    output_lines = []

    # 1. ì—­ëŸ‰ ê´€ê³„ë§ ê·¸ë˜í”„ ìƒì„±
    print("Step 1: ì—­ëŸ‰ ê´€ê³„ë§ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤...")
    skill_graph = build_skill_graph(df)
    print(f"Graph Generated [Node: {skill_graph.number_of_nodes()}, Edge: {skill_graph.number_of_edges()}]\n")

    if df is not None and not df.empty:
        comp_unit_id = "2001030406" # input("ëŠ¥ë ¥ë‹¨ìœ„ ID (ì‰¼í‘œë¡œ êµ¬ë¶„): ")
        comp_unit_ids = [s.strip() for s in comp_unit_id.split(',')]
        target_comp_unit_id = "2001030407" # input("íƒ€ê²Ÿ ID: ")

        if not all(s_id in skill_graph.nodes for s_id in comp_unit_ids):
            missing_ids = [s_id for s_id in comp_unit_ids if s_id not in skill_graph.nodes]
            print(f"ì˜¤ë¥˜: ì…ë ¥í•œ ëŠ¥ë ¥ë‹¨ìœ„ ID ì¤‘ ë‹¤ìŒ ID(ë“¤)ì´ ê·¸ë˜í”„ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {', '.join(missing_ids)}. ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
            exit(0)

        if target_comp_unit_id not in skill_graph.nodes:
            print(f"ì…ë ¥í•œ íƒ€ê²Ÿ ëŠ¥ë ¥ë‹¨ìœ„ ID '{target_comp_unit_id}'ê°€ ê·¸ë˜í”„ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            exit(0)

        # ë¶„ì„ ì‹œì‘ ë©”ì‹œì§€ëŠ” íŒŒì¼ì—ë„ í¬í•¨
        output_lines.append("=" * 70)
        output_lines.append(f"â–¶ ë¶„ì„ ìš”ì²­ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output_lines.append("=" * 70)

        output_lines.append("\n[ìµœì  ê²½ë¡œ ë° ìŠ¤í‚¬ ê°­ ë¶„ì„]")
        output_lines.append(f"â–¶ í˜„ì¬ ë³´ìœ  ì—­ëŸ‰")
        for s in comp_unit_ids:
            output_lines.append(f"\t- {skill_graph.nodes[s]['name']} (Level {skill_graph.nodes[s]['level']})")
        output_lines.append(f"\nâ–¶ ëª©í‘œ ì—­ëŸ‰")
        output_lines.append(f"\t- {skill_graph.nodes[target_comp_unit_id]['name']} (Level {skill_graph.nodes[target_comp_unit_id]['level']})\n")

        # 3. ê²½ë¡œ íƒìƒ‰ ë° ê²°ê³¼ ì¶œë ¥
        recommended_path, skill_gap = find_career_path(skill_graph, comp_unit_ids, target_comp_unit_id)
        current_lecture_set = set()
        target_lecture_set = set()

        if recommended_path:
            output_lines.append("[ë¶„ì„ ê²°ê³¼]")
            output_lines.append("ğŸš€ ë‹¹ì‹ ì„ ìœ„í•œ ì¶”ì²œ ì„±ì¥ ë¡œë“œë§µ ğŸš€")

            for i, skill_id in enumerate(recommended_path):
                node = skill_graph.nodes[skill_id]
                status = "âœ… (ë³´ìœ )" if skill_id in comp_unit_ids else "ğŸ¯ (í•™ìŠµ í•„ìš”)"
                output_lines.append(f"\t- {i + 1}. {node['name']} (Level {node['level']}) {status}")

            output_lines.append("\nğŸ’¡í˜„ì¬ ë³´ìœ í•œ ì—­ëŸ‰ ê´€ë ¨ ê°•ì˜")
            courses = get_course_from_node(comp_unit_id, engine)
            for course in courses:
                if course not in current_lecture_set:
                    output_lines.append(f"\t- {course}")
                    current_lecture_set.add(course)

            output_lines.append("\nğŸ’¡ìŠ¤í‚¬ ê°­(Skill Gap)")
            for skill_id in skill_gap:
                node = skill_graph.nodes[skill_id]
                output_lines.append(f"{node['name']} (Level {node['level']})")
                courses = get_course_from_node(skill_id, engine)

                for course in courses:
                    if course not in target_lecture_set:
                        output_lines.append(f"\t- {course}")
                        target_lecture_set.add(course)

                output_lines.append("\n")

        else:
            output_lines.append("ë¶„ì„ ì‹¤íŒ¨: ëª©í‘œ ì—­ëŸ‰ê¹Œì§€ ë„ë‹¬ ê°€ëŠ¥í•œ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # --- í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œì ì— íŒŒì¼ ì €ì¥ ---
        ANALYSIS_DIR_PATH.mkdir(parents=True, exist_ok=True)  # ê²°ê³¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ ìƒì„±

        # íŒŒì¼ëª…ì— í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ í¬í•¨
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = ANALYSIS_DIR_PATH / f"skill_analysis_report_{timestamp}.txt"

        with open(output_filename, "w", encoding="utf-8") as f:
            f.write('\n'.join(output_lines))

        print(f"\në¶„ì„ ê²°ê³¼ê°€ '{output_filename}' íŒŒì¼ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
